{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import joblib\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Load dataset (Update path if needed)\n",
        "file_path = 'WA_Fn-UseC_-Telco-Customer-Churn.csv'  # Make sure it's in the same directory\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"File '{file_path}' not found!\")\n",
        "\n",
        "data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Clean data\n",
        "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
        "data.drop('customerID', axis=1, inplace=True)\n",
        "data['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Feature Engineering\n",
        "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "categorical_features = [col for col in data.columns if col not in numerical_features + ['Churn']]\n",
        "\n",
        "X = data.drop('Churn', axis=1)\n",
        "y = data['Churn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: Pipelines for preprocessing\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipeline, numerical_features),\n",
        "    ('cat', cat_pipeline, categorical_features)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Full pipeline with a placeholder model\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: Grid search parameters\n",
        "param_grid = [\n",
        "    {\n",
        "        'classifier': [LogisticRegression(max_iter=1000, class_weight='balanced')],\n",
        "        'classifier__C': [0.1, 1, 10],\n",
        "        'classifier__penalty': ['l2']\n",
        "    },\n",
        "    {\n",
        "        'classifier': [RandomForestClassifier(class_weight='balanced', random_state=42)],\n",
        "        'classifier__n_estimators': [100, 200],\n",
        "        'classifier__max_depth': [10, 20, None],\n",
        "        'classifier__min_samples_split': [2, 5]\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "Best Parameters: {'classifier': RandomForestClassifier(class_weight='balanced', random_state=42), 'classifier__max_depth': 10, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
            "Best F1-Score on CV: 0.6364589941138907\n"
          ]
        }
      ],
      "source": [
        "# Step 9: Train using GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best F1-Score on CV:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Test Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.77      0.83      1035\n",
            "           1       0.54      0.74      0.62       374\n",
            "\n",
            "    accuracy                           0.76      1409\n",
            "   macro avg       0.72      0.76      0.73      1409\n",
            "weighted avg       0.80      0.76      0.77      1409\n",
            "\n",
            "AUC-ROC Score: 0.8395864010953524\n"
          ]
        }
      ],
      "source": [
        "# Step 10: Evaluate on test data\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nðŸ“Š Test Set Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"AUC-ROC Score:\", roc_auc_score(y_test, y_pred_proba))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model saved as 'churn_pipeline.pkl'\n"
          ]
        }
      ],
      "source": [
        "# Step 11: Save the model\n",
        "joblib.dump(best_model, 'churn_pipeline.pkl')\n",
        "print(\"\\nModel saved as 'churn_pipeline.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Prediction: No Churn\n"
          ]
        }
      ],
      "source": [
        "# Step 12: Load and predict a sample\n",
        "loaded_model = joblib.load('churn_pipeline.pkl')\n",
        "sample = X_test.iloc[[0]]\n",
        "sample_prediction = loaded_model.predict(sample)[0]\n",
        "print(\"\\nSample Prediction:\", \"Churn\" if sample_prediction else \"No Churn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
